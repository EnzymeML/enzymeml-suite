{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33aefc8f",
   "metadata": {},
   "source": [
    "# Surrogate-Accelerated Bayesian Inference with Catalax\n",
    "\n",
    "This template demonstrates how to perform surrogate-accelerated Bayesian parameter estimation for enzyme kinetic models using the Catalax JAX library. This approach combines the power of Bayesian inference with Neural ODE surrogate models to dramatically speed up parameter estimation while maintaining uncertainty quantification.\n",
    "\n",
    "## What is Surrogate-Accelerated Bayesian Inference?\n",
    "\n",
    "Surrogate-accelerated Bayesian inference uses fast neural network approximations (surrogates) of expensive differential equation models to speed up Bayesian parameter estimation. Instead of solving the full ODE system at each MCMC step, we use a pre-trained Neural ODE surrogate that can evaluate the model orders of magnitude faster.\n",
    "\n",
    "The key advantages of surrogate-accelerated Bayesian inference include:\n",
    "\n",
    "- **Dramatic Speed Improvements**: Neural ODE surrogates can be 100-1000x faster than traditional ODE solvers\n",
    "- **Maintained Accuracy**: Well-trained surrogates preserve the accuracy of the original model\n",
    "- **Full Uncertainty Quantification**: Get confidence intervals and credible regions for your parameters\n",
    "- **Prior Knowledge Integration**: Incorporate existing knowledge about parameter ranges\n",
    "- **Robust Predictions**: Make predictions that account for parameter uncertainty\n",
    "\n",
    "## Neural ODE Surrogates\n",
    "\n",
    "Neural ODEs combine neural networks with differential equations, learning to approximate the dynamics of complex systems. In this context, they serve as fast approximations of enzyme kinetic models, enabling rapid evaluation during MCMC sampling while preserving the underlying physics.\n",
    "\n",
    "## Surrogate Hamiltonian Monte Carlo (Surrogate HMC)\n",
    "\n",
    "This template uses Surrogate Hamiltonian Monte Carlo, which combines HMC sampling with Neural ODE surrogates. The surrogate model is first trained on the original ODE system, then used during MCMC to dramatically accelerate the sampling process while maintaining statistical rigor.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "This template provides the basic code to get you started with Bayesian inference using Catalax. In order to ensure that the template works, you need to assign prior distributions to the parameters. In the follwing is an example of how to assign prior distributions to the parameters.\n",
    "\n",
    "```python\n",
    "import catalax.mcmc as cmc\n",
    "\n",
    "model.parameters[\"v_max\"].prior = cmc.Normal(mu=0.0, sigma=1.0)\n",
    "```\n",
    "\n",
    "Surrogate-accelerated Bayesian inference **requires** a trained Neural ODE surrogate model. We recommend using the **Neural ODE template** first to train the surrogate model. Learn more about surrogate-accelerated Bayesian inference with Catalax in the [Catalax documentation](https://catalax.mintlify.app/hmc/surrogate-hmc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all required packages\n",
    "%pip install pyenzyme catalax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de39726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyenzyme as pe\n",
    "import catalax as ctx\n",
    "import catalax.mcmc as cmc\n",
    "import catalax.neural as ctn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b9f95a",
   "metadata": {},
   "source": [
    "In the following cell, we will load the EnzymML document from the EnzymeML Suite. The resulting object is an instance of the `EnzymeMLDocument` class, which you can inspect and re-use for your analysis. The following functions are available and compatible with the EnzymeMLDocument class:\n",
    "\n",
    "- `pe.summary(enzmldoc)`: Print a summary of the EnzymeML document.\n",
    "- `pe.plot(enzmldoc)`: Plot the EnzymeML document.\n",
    "- `pe.plot_interactive(enzmldoc)`: Interactive plot of the EnzymeML document.\n",
    "- `pe.to_pandas(enzmldoc)`: Convert the EnzymeML document to a pandas DataFrame.\n",
    "- `pe.to_sbml(enzmldoc)`: Convert the EnzymeML document to an SBML document.\n",
    "- `pe.to_petab(enzmldoc)`: Convert the EnzymeML document to a PEtab format.\n",
    "- `pe.get_current()`: Get the current EnzymeML document from the EnzymeML Suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9307ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the EnzymeML Suite\n",
    "suite = pe.EnzymeMLSuite()\n",
    "\n",
    "# Get the current EnzymeML document\n",
    "enzmldoc = suite.get_current()\n",
    "\n",
    "# Print a summary of the EnzymeML document\n",
    "pe.summary(enzmldoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fdf68a",
   "metadata": {},
   "source": [
    "## Converting EnzymeML to Catalax\n",
    "\n",
    "The `ctx.from_enzymeml` function converts an EnzymeML document to a Catalax dataset and model objects. The dataset contains the experimental data, and the model is a Catalax model object that you can use for parameter estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3c44b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, model = ctx.from_enzymeml(enzmldoc)\n",
    "\n",
    "# Load the trained Neural ODE surrogate model (adjust the path to the correct file)\n",
    "trained = ctn.NeuralODE.from_eqx(\"trained_neural_ode.eqx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e89b1f1",
   "metadata": {},
   "source": [
    "## Bayesian Inference\n",
    "\n",
    "The `ctx.optimize` function performs parameter estimation using the specified optimization algorithm. The function returns the optimized parameters, the optimized model, and the optimization history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d900d1c8",
   "metadata": {},
   "source": [
    "### Step 1: Set the prior distributions for the parameters\n",
    "\n",
    "Before running the MCMC simulation, we need to set the prior distributions for the parameters. A prior distribution is a probability distribution that represents our beliefs about the parameters before we have any data. For instance, if you believe that a parameter is between 1 and 10, you can set a uniform prior distribution for that parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe31a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters.values():\n",
    "    # We are setting a very wide uniform prior to the parameters\n",
    "    # This is a placeholder and should be replaced with a more informative prior\n",
    "    param.prior = cmc.priors.Uniform(low=1e-6, high=1e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8444ea",
   "metadata": {},
   "source": [
    "### Step 2: Perform MCMC simulation\n",
    "\n",
    "Now we can perform the MCMC simulation, by using the `cmc.HMC` class. You can customize the sampling process by changing the parameters of the `cmc.HMC` class:\n",
    "\n",
    "- `num_warmup`: The number of warmup samples.\n",
    "- `num_samples`: The number of samples to draw from the posterior distribution.\n",
    "- `dt0`: The initial step size.\n",
    "- `max_steps`: The maximum number of steps.\n",
    "- `verbose`: The verbosity level.\n",
    "\n",
    "In contrast to the usual HMC workflow, we will pass the trained Neural ODE surrogate model to the `cmc.HMC.run` function via the `surrogate` argument.\n",
    "\n",
    "**Tips**\n",
    "\n",
    "- HMC is very efficient, you dont need millions of samples to get a good posterior distribution.\n",
    "- If the resulting sampling fails (indicated by `Rhat > 1.01`), you can try to increase the number of warmup samples or the number of samples.\n",
    "- The choice of prior distributions is crucial for the quality of the posterior distribution. Use literature values if possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63bb537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform MCMC simulation\n",
    "hmc = cmc.HMC(\n",
    "    num_warmup=1000,\n",
    "    num_samples=1000,\n",
    "    dt0=0.1,\n",
    "    max_steps=64**4,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "results = hmc.run(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    yerrs=2.0,\n",
    "    surrogate=trained,\n",
    ")\n",
    "\n",
    "# Return the fitted model\n",
    "fitted_model = results.get_fitted_model()\n",
    "\n",
    "# Print the summary\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcf903a",
   "metadata": {},
   "source": [
    "### Step 3: Diagnostics\n",
    "\n",
    "Now that our Bayesian inference is done, we can visualize the results using common diagnistical plots. Using all is out of the scope of this template, but you can find more information in the [Catalax documentation](https://catalax.mintlify.app/hmc/mcmc-basic). We will use a corner plot to visualize the posterior distribution and cross-correlation of the parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e1c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot_corner(show=True, path=\"bayesian_inference_corner.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0d877b",
   "metadata": {},
   "source": [
    "We can now also visualize the model fit to the data. Note, that this plot will display the uncertanties of the parameters as bands. Medium opaque bands correspond to 50% credibility intervals, and light opaque bands correspond to 95% credibility intervals. Wide bands indicate high uncertainty, and point to insufficient data or an overparameterized model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9af17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the optimized model fit to the data\n",
    "dataset.plot(\n",
    "    predictor=fitted_model,\n",
    "    show=True,\n",
    "    path=\"bayesian_inference.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f375ad",
   "metadata": {},
   "source": [
    "## Update the EnzymeML Suite document\n",
    "\n",
    "Once done, we can update the EnzymeML Suite document with the optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38dd545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will update the model with the optimized parameters\n",
    "updated_enzmldoc = fitted_model.to_enzymeml(enzmldoc)\n",
    "\n",
    "# And update the EnzymeML Suite document\n",
    "suite.update_current(updated_enzmldoc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catalax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
